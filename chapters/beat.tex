\chapter{How to beat the system}
The method described in this thesis has some weaknesses. I will construct a dateset, which is not processed very well and I will discuss, why this type of data is not very common.

\section{Constructing a special dataset}\label{sec:constr}
Consider the following a dataset, that is made of many random points $(x, y, z) \in \left[0, 1\right)^3$, that satisfy the following constraint:
\begin{equation}\label{eq:beat}
	(x + y + z) \bmod 1 = 0
\end{equation}
The points are uniform distributed if you project them on one or two dimensions. But if you calculate the three dimensional distribution, the points do not show a uniform distribution. (see Figure~\ref{fig:beat}). Because the generated points have two degrees of freedom, the two dimensional distribution test will fail. It is also possible to generate datasets with even more degrees of freedom using the same technique.\footnote{You may not be able to imagine datasets with more than three dimensions. For 4 dimensions, you find some help: \url{http://crepererum.github.io/brain4D/\#constructed}}
\begin{figure}
	\caption{Situation described in Equation~\ref{eq:beat}}
	\label{fig:beat}
	\subfloat[\label{subfig:beat1}1D views]{\input{figures/beat1.tex}}
	\hfill
	\subfloat[\label{subfig:beat2}2D views]{\input{figures/beat2.tex}}
	\hfill
	\subfloat[\label{subfig:beat3}3D view]{\input{figures/beat3.tex}}
	\hfill
\end{figure}

The problem occures every time, when the dataset contains a subspace with $n \in \set{N}_+$ Dimensions but $m \in \left\{1,\dots,n-1\right\}$ degrees of freedom. Furthermore the dependency of each dimension on the degrees of freedom has to be equal.

\section{Handling this issue}
Because it datasets with generated dimensions are not very uncommon, I will propose a simple method to handle them. To get a good perfomance on high dimensional datasets, it is not possible to check distributions in subspaces where the size depends on the number of all dimensions. But as shown in \cite{journals/prl/SharmaP07}, a PCA can be computed in $O\left( d^2h + d^2n \right)$ where $h$ is the number of degrees of freedom. After this step, the algorithm will find the most common subspaces.

